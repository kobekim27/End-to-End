{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56b6edb6-31bd-40d1-8b11-00da29e31079",
   "metadata": {},
   "source": [
    "# Project Outline\n",
    "\n",
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "4c69305c-5673-49bd-9d37-c6a310e53a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age         workclass  fnlwgt  education  education_num  \\\n",
      "0   39         State-gov   77516  Bachelors             13   \n",
      "1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
      "2   38           Private  215646    HS-grad              9   \n",
      "3   53           Private  234721       11th              7   \n",
      "4   28           Private  338409  Bachelors             13   \n",
      "\n",
      "       marital_status         occupation   relationship   race     sex  \\\n",
      "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
      "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
      "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
      "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
      "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
      "\n",
      "   capital_gain  capital_loss  hours_per_week native_country income  \n",
      "0          2174             0              40  United-States  <=50K  \n",
      "1             0             0              13  United-States  <=50K  \n",
      "2             0             0              40  United-States  <=50K  \n",
      "3             0             0              40  United-States  <=50K  \n",
      "4             0             0              40           Cuba  <=50K  \n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Step 1: Load and parse the CSV file\n",
    "file_path = 'adult-all.csv' #https://github.com/jbrownlee/Datasets/blob/master/adult-all.csv\n",
    "data = []\n",
    "columns = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', \n",
    "           'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', \n",
    "           'hours-per-week', 'native-country', 'income']\n",
    "\n",
    "with open(file_path, mode='r') as file:\n",
    "    csv_reader = csv.reader(file)\n",
    "    for row in csv_reader:\n",
    "        data.append(dict(zip(columns, row)))\n",
    "\n",
    "# Step 2: Create a normalized database\n",
    "conn = sqlite3.connect(':memory:')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Create tables for categorical data\n",
    "cursor.execute('''CREATE TABLE workclass (id INTEGER PRIMARY KEY, workclass TEXT UNIQUE)''')\n",
    "cursor.execute('''CREATE TABLE education (id INTEGER PRIMARY KEY, education TEXT UNIQUE)''')\n",
    "cursor.execute('''CREATE TABLE marital_status (id INTEGER PRIMARY KEY, marital_status TEXT UNIQUE)''')\n",
    "cursor.execute('''CREATE TABLE occupation (id INTEGER PRIMARY KEY, occupation TEXT UNIQUE)''')\n",
    "cursor.execute('''CREATE TABLE relationship (id INTEGER PRIMARY KEY, relationship TEXT UNIQUE)''')\n",
    "cursor.execute('''CREATE TABLE race (id INTEGER PRIMARY KEY, race TEXT UNIQUE)''')\n",
    "cursor.execute('''CREATE TABLE sex (id INTEGER PRIMARY KEY, sex TEXT UNIQUE)''')\n",
    "cursor.execute('''CREATE TABLE native_country (id INTEGER PRIMARY KEY, native_country TEXT UNIQUE)''')\n",
    "\n",
    "# Create main table\n",
    "cursor.execute('''CREATE TABLE adult_data \n",
    "               (id INTEGER PRIMARY KEY, \n",
    "               age INTEGER, \n",
    "               workclass_id INTEGER,\n",
    "               fnlwgt INTEGER,\n",
    "               education_id INTEGER,\n",
    "               education_num INTEGER,\n",
    "               marital_status_id INTEGER,\n",
    "               occupation_id INTEGER,\n",
    "               relationship_id INTEGER,\n",
    "               race_id INTEGER,\n",
    "               sex_id INTEGER,\n",
    "               capital_gain INTEGER,\n",
    "               capital_loss INTEGER,\n",
    "               hours_per_week INTEGER,\n",
    "               native_country_id INTEGER,\n",
    "               income TEXT)''')\n",
    "\n",
    "# Insert data into tables\n",
    "for row in data:\n",
    "    cursor.execute(\"INSERT OR IGNORE INTO workclass (workclass) VALUES (?)\", (row['workclass'],))\n",
    "    cursor.execute(\"INSERT OR IGNORE INTO education (education) VALUES (?)\", (row['education'],))\n",
    "    cursor.execute(\"INSERT OR IGNORE INTO marital_status (marital_status) VALUES (?)\", (row['marital-status'],))\n",
    "    cursor.execute(\"INSERT OR IGNORE INTO occupation (occupation) VALUES (?)\", (row['occupation'],))\n",
    "    cursor.execute(\"INSERT OR IGNORE INTO relationship (relationship) VALUES (?)\", (row['relationship'],))\n",
    "    cursor.execute(\"INSERT OR IGNORE INTO race (race) VALUES (?)\", (row['race'],))\n",
    "    cursor.execute(\"INSERT OR IGNORE INTO sex (sex) VALUES (?)\", (row['sex'],))\n",
    "    cursor.execute(\"INSERT OR IGNORE INTO native_country (native_country) VALUES (?)\", (row['native-country'],))\n",
    "    \n",
    "    cursor.execute('''INSERT INTO adult_data \n",
    "                   (age, workclass_id, fnlwgt, education_id, education_num, marital_status_id,\n",
    "                   occupation_id, relationship_id, race_id, sex_id, capital_gain, capital_loss,\n",
    "                   hours_per_week, native_country_id, income)\n",
    "                   VALUES \n",
    "                   (?, (SELECT id FROM workclass WHERE workclass = ?),\n",
    "                   ?, (SELECT id FROM education WHERE education = ?),\n",
    "                   ?, (SELECT id FROM marital_status WHERE marital_status = ?),\n",
    "                   (SELECT id FROM occupation WHERE occupation = ?),\n",
    "                   (SELECT id FROM relationship WHERE relationship = ?),\n",
    "                   (SELECT id FROM race WHERE race = ?),\n",
    "                   (SELECT id FROM sex WHERE sex = ?),\n",
    "                   ?, ?, ?, (SELECT id FROM native_country WHERE native_country = ?), ?)''',\n",
    "                   (row['age'], row['workclass'], row['fnlwgt'], row['education'], row['education-num'],\n",
    "                    row['marital-status'], row['occupation'], row['relationship'], row['race'],\n",
    "                    row['sex'], row['capital-gain'], row['capital-loss'], row['hours-per-week'],\n",
    "                    row['native-country'], row['income']))\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "# Step 3: Write an SQL query with joins to reconstruct the data\n",
    "query = '''\n",
    "SELECT ad.age, w.workclass, ad.fnlwgt, e.education, ad.education_num, \n",
    "       ms.marital_status, o.occupation, r.relationship, rc.race, s.sex, \n",
    "       ad.capital_gain, ad.capital_loss, ad.hours_per_week, nc.native_country, ad.income\n",
    "FROM adult_data ad\n",
    "JOIN workclass w ON ad.workclass_id = w.id\n",
    "JOIN education e ON ad.education_id = e.id\n",
    "JOIN marital_status ms ON ad.marital_status_id = ms.id\n",
    "JOIN occupation o ON ad.occupation_id = o.id\n",
    "JOIN relationship r ON ad.relationship_id = r.id\n",
    "JOIN race rc ON ad.race_id = rc.id\n",
    "JOIN sex s ON ad.sex_id = s.id\n",
    "JOIN native_country nc ON ad.native_country_id = nc.id\n",
    "'''\n",
    "\n",
    "# Load the result into a Pandas DataFrame\n",
    "data = pd.read_sql_query(query, conn)\n",
    "\n",
    "# Display the first five of the DataFrame\n",
    "print(data.head())\n",
    "\n",
    "# Close the database connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "b7acb211-b1b6-4868-b90c-459b74f133d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       age         workclass  fnlwgt  education  education_num  \\\n",
      "0       39         State-gov   77516  Bachelors             13   \n",
      "1       50  Self-emp-not-inc   83311  Bachelors             13   \n",
      "2       38           Private  215646    HS-grad              9   \n",
      "3       53           Private  234721       11th              7   \n",
      "4       28           Private  338409  Bachelors             13   \n",
      "...    ...               ...     ...        ...            ...   \n",
      "48837   39           Private  215419  Bachelors             13   \n",
      "48838   64                 ?  321403    HS-grad              9   \n",
      "48839   38           Private  374983  Bachelors             13   \n",
      "48840   44           Private   83891  Bachelors             13   \n",
      "48841   35      Self-emp-inc  182148  Bachelors             13   \n",
      "\n",
      "           marital_status         occupation    relationship  \\\n",
      "0           Never-married       Adm-clerical   Not-in-family   \n",
      "1      Married-civ-spouse    Exec-managerial         Husband   \n",
      "2                Divorced  Handlers-cleaners   Not-in-family   \n",
      "3      Married-civ-spouse  Handlers-cleaners         Husband   \n",
      "4      Married-civ-spouse     Prof-specialty            Wife   \n",
      "...                   ...                ...             ...   \n",
      "48837            Divorced     Prof-specialty   Not-in-family   \n",
      "48838             Widowed                  ?  Other-relative   \n",
      "48839  Married-civ-spouse     Prof-specialty         Husband   \n",
      "48840            Divorced       Adm-clerical       Own-child   \n",
      "48841  Married-civ-spouse    Exec-managerial         Husband   \n",
      "\n",
      "                     race     sex  capital_gain  capital_loss  hours_per_week  \\\n",
      "0                   White    Male          2174             0              40   \n",
      "1                   White    Male             0             0              13   \n",
      "2                   White    Male             0             0              40   \n",
      "3                   Black    Male             0             0              40   \n",
      "4                   Black  Female             0             0              40   \n",
      "...                   ...     ...           ...           ...             ...   \n",
      "48837               White  Female             0             0              36   \n",
      "48838               Black    Male             0             0              40   \n",
      "48839               White    Male             0             0              50   \n",
      "48840  Asian-Pac-Islander    Male          5455             0              40   \n",
      "48841               White    Male             0             0              60   \n",
      "\n",
      "      native_country income  \n",
      "0      United-States  <=50K  \n",
      "1      United-States  <=50K  \n",
      "2      United-States  <=50K  \n",
      "3      United-States  <=50K  \n",
      "4               Cuba  <=50K  \n",
      "...              ...    ...  \n",
      "48837  United-States  <=50K  \n",
      "48838  United-States  <=50K  \n",
      "48839  United-States  <=50K  \n",
      "48840  United-States  <=50K  \n",
      "48841  United-States   >50K  \n",
      "\n",
      "[48842 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "19a91512-b38d-4b64-aa04-ae089eb27259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48842 entries, 0 to 48841\n",
      "Data columns (total 15 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   age             48842 non-null  int64 \n",
      " 1   workclass       48842 non-null  object\n",
      " 2   fnlwgt          48842 non-null  int64 \n",
      " 3   education       48842 non-null  object\n",
      " 4   education_num   48842 non-null  int64 \n",
      " 5   marital_status  48842 non-null  object\n",
      " 6   occupation      48842 non-null  object\n",
      " 7   relationship    48842 non-null  object\n",
      " 8   race            48842 non-null  object\n",
      " 9   sex             48842 non-null  object\n",
      " 10  capital_gain    48842 non-null  int64 \n",
      " 11  capital_loss    48842 non-null  int64 \n",
      " 12  hours_per_week  48842 non-null  int64 \n",
      " 13  native_country  48842 non-null  object\n",
      " 14  income          48842 non-null  object\n",
      "dtypes: int64(6), object(9)\n",
      "memory usage: 5.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "7492e96b-abc8-4f66-b313-de80f1de2a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign column names\n",
    "columns = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', \n",
    "           'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', \n",
    "           'hours-per-week', 'native-country', 'income']\n",
    "data.columns = columns\n",
    "\n",
    "# Remove whitespace from string columns\n",
    "string_columns = ['workclass', 'education', 'marital-status', 'occupation', \n",
    "                  'relationship', 'race', 'sex', 'native-country', 'income']\n",
    "for column in string_columns:\n",
    "    data[column] = data[column].str.strip()\n",
    "\n",
    "# Remove rows with missing data\n",
    "data_cleaned = data.dropna()\n",
    "\n",
    "# Replace '?' with 'unknown'\n",
    "data_cleaned = data.replace('?', 'unknown')\n",
    "\n",
    "# Standardize strings (convert to lowercase)\n",
    "for column in string_columns:\n",
    "    data_cleaned[column] = data_cleaned[column].str.lower()\n",
    "\n",
    "# Correct column data types\n",
    "data_cleaned['age'] = data_cleaned['age'].astype(int)\n",
    "data_cleaned['fnlwgt'] = data_cleaned['fnlwgt'].astype(int)\n",
    "data_cleaned['education-num'] = data_cleaned['education-num'].astype(int)\n",
    "data_cleaned['capital-gain'] = data_cleaned['capital-gain'].astype(int)\n",
    "data_cleaned['capital-loss'] = data_cleaned['capital-loss'].astype(int)\n",
    "data_cleaned['hours-per-week'] = data_cleaned['hours-per-week'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "41a29654-5edf-4c5a-b6fa-31abf457649e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"C:\\Users\\pogoz\\anaconda3\\lib\\runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 460, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 367, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 662, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 360, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2914, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2960, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 78, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3185, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3377, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\pogoz\\AppData\\Local\\Temp\\ipykernel_18052\\2554771686.py\", line 1, in <module>\n",
      "    from sklearn.preprocessing import LabelEncoder\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\sklearn\\__init__.py\", line 73, in <module>\n",
      "    from .base import clone  # noqa: E402\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 19, in <module>\n",
      "    from .utils._estimator_html_repr import _HTMLDocumentationLinkMixin, estimator_html_repr\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\sklearn\\utils\\__init__.py\", line 15, in <module>\n",
      "    from ._chunking import gen_batches, gen_even_slices\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_chunking.py\", line 11, in <module>\n",
      "    from ._param_validation import Interval, validate_params\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 14, in <module>\n",
      "    from scipy.sparse import csr_matrix, issparse\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\scipy\\sparse\\__init__.py\", line 228, in <module>\n",
      "    from .csr import *\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\scipy\\sparse\\csr.py\", line 10, in <module>\n",
      "    from ._sparsetools import (csr_tocsc, csr_tobsr, csr_count_blocks,\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core.multiarray failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18052\\2554771686.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Create a LabelEncoder object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[0m_distributor_init\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m )\n\u001b[1;32m---> 73\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mclone\u001b[0m  \u001b[1;31m# noqa: E402\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_show_versions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mshow_versions\u001b[0m  \u001b[1;31m# noqa: E402\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_config\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInconsistentVersionWarning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_estimator_html_repr\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_HTMLDocumentationLinkMixin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimator_html_repr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_metadata_requests\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_MetadataRequester\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_routing_enabled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_param_validation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mvalidate_parameter_constraints\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_joblib\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetadata_routing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_bunch\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBunch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_chunking\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgen_batches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgen_even_slices\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_estimator_html_repr\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mestimator_html_repr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_chunking.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_config\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_param_validation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInterval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate_params\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcsr_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_config\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 228\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mcsr\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    229\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mcsc\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mlil\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\csr.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mspmatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m from ._sparsetools import (csr_tocsc, csr_tobsr, csr_count_blocks,\n\u001b[0m\u001b[0;32m     11\u001b[0m                            get_csr_submatrix)\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0msputils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mupcast\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_index_dtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: numpy.core.multiarray failed to import"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "# Create a LabelEncoder object\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Apply Label Encoding to the 'education' column\n",
    "data_cleaned['education_encoded'] = le.fit_transform(data_cleaned['education'])\n",
    "\n",
    "# Display the first few rows to verify the encoding\n",
    "print(data_cleaned[['education', 'education_encoded']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "77b55ee0-3029-4a0b-af75-23eb70821dfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "9afb43a9-0273-4727-bf88-c16f8a767bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       age  fnlwgt  education-num  capital-gain  capital-loss  hours-per-week  \\\n",
      "0       39   77516             13          2174             0              40   \n",
      "1       50   83311             13             0             0              13   \n",
      "2       38  215646              9             0             0              40   \n",
      "3       53  234721              7             0             0              40   \n",
      "4       28  338409             13             0             0              40   \n",
      "...    ...     ...            ...           ...           ...             ...   \n",
      "48837   39  215419             13             0             0              36   \n",
      "48838   64  321403              9             0             0              40   \n",
      "48839   38  374983             13             0             0              50   \n",
      "48840   44   83891             13          5455             0              40   \n",
      "48841   35  182148             13             0             0              60   \n",
      "\n",
      "       income  workclass_local-gov  workclass_never-worked  workclass_private  \\\n",
      "0           0                False                   False              False   \n",
      "1           0                False                   False              False   \n",
      "2           0                False                   False               True   \n",
      "3           0                False                   False               True   \n",
      "4           0                False                   False               True   \n",
      "...       ...                  ...                     ...                ...   \n",
      "48837       0                False                   False               True   \n",
      "48838       0                False                   False              False   \n",
      "48839       0                False                   False               True   \n",
      "48840       0                False                   False               True   \n",
      "48841       0                False                   False              False   \n",
      "\n",
      "       ...  native-country_puerto-rico  native-country_scotland  \\\n",
      "0      ...                       False                    False   \n",
      "1      ...                       False                    False   \n",
      "2      ...                       False                    False   \n",
      "3      ...                       False                    False   \n",
      "4      ...                       False                    False   \n",
      "...    ...                         ...                      ...   \n",
      "48837  ...                       False                    False   \n",
      "48838  ...                       False                    False   \n",
      "48839  ...                       False                    False   \n",
      "48840  ...                       False                    False   \n",
      "48841  ...                       False                    False   \n",
      "\n",
      "       native-country_south  native-country_taiwan  native-country_thailand  \\\n",
      "0                     False                  False                    False   \n",
      "1                     False                  False                    False   \n",
      "2                     False                  False                    False   \n",
      "3                     False                  False                    False   \n",
      "4                     False                  False                    False   \n",
      "...                     ...                    ...                      ...   \n",
      "48837                 False                  False                    False   \n",
      "48838                 False                  False                    False   \n",
      "48839                 False                  False                    False   \n",
      "48840                 False                  False                    False   \n",
      "48841                 False                  False                    False   \n",
      "\n",
      "       native-country_trinadad&tobago  native-country_united-states  \\\n",
      "0                               False                          True   \n",
      "1                               False                          True   \n",
      "2                               False                          True   \n",
      "3                               False                          True   \n",
      "4                               False                         False   \n",
      "...                               ...                           ...   \n",
      "48837                           False                          True   \n",
      "48838                           False                          True   \n",
      "48839                           False                          True   \n",
      "48840                           False                          True   \n",
      "48841                           False                          True   \n",
      "\n",
      "       native-country_unknown  native-country_vietnam  \\\n",
      "0                       False                   False   \n",
      "1                       False                   False   \n",
      "2                       False                   False   \n",
      "3                       False                   False   \n",
      "4                       False                   False   \n",
      "...                       ...                     ...   \n",
      "48837                   False                   False   \n",
      "48838                   False                   False   \n",
      "48839                   False                   False   \n",
      "48840                   False                   False   \n",
      "48841                   False                   False   \n",
      "\n",
      "       native-country_yugoslavia  \n",
      "0                          False  \n",
      "1                          False  \n",
      "2                          False  \n",
      "3                          False  \n",
      "4                          False  \n",
      "...                          ...  \n",
      "48837                      False  \n",
      "48838                      False  \n",
      "48839                      False  \n",
      "48840                      False  \n",
      "48841                      False  \n",
      "\n",
      "[48842 rows x 101 columns]\n"
     ]
    }
   ],
   "source": [
    "# Display the cleaned dataset info\n",
    "print(data_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "723c37de-7abf-4ec3-9727-99a19a72f91a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48842 entries, 0 to 48841\n",
      "Data columns (total 15 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   age             48842 non-null  int64 \n",
      " 1   workclass       48842 non-null  object\n",
      " 2   fnlwgt          48842 non-null  int64 \n",
      " 3   education       48842 non-null  object\n",
      " 4   education-num   48842 non-null  int64 \n",
      " 5   marital-status  48842 non-null  object\n",
      " 6   occupation      48842 non-null  object\n",
      " 7   relationship    48842 non-null  object\n",
      " 8   race            48842 non-null  object\n",
      " 9   sex             48842 non-null  object\n",
      " 10  capital-gain    48842 non-null  int64 \n",
      " 11  capital-loss    48842 non-null  int64 \n",
      " 12  hours-per-week  48842 non-null  int64 \n",
      " 13  native-country  48842 non-null  object\n",
      " 14  income          48842 non-null  object\n",
      "dtypes: int64(6), object(9)\n",
      "memory usage: 5.6+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Display the cleaned dataset info\n",
    "print(data_cleaned.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "34569214-cad1-4227-b2e4-63ee7bea120c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "income\n",
       "<=50k    37155\n",
       ">50k     11687\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cleaned[\"income\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "a238ef33-a14d-4cd1-b5c5-7ac42c262eb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>48842.000000</td>\n",
       "      <td>4.884200e+04</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38.643585</td>\n",
       "      <td>1.896641e+05</td>\n",
       "      <td>10.078089</td>\n",
       "      <td>1079.067626</td>\n",
       "      <td>87.502314</td>\n",
       "      <td>40.422382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.710510</td>\n",
       "      <td>1.056040e+05</td>\n",
       "      <td>2.570973</td>\n",
       "      <td>7452.019058</td>\n",
       "      <td>403.004552</td>\n",
       "      <td>12.391444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.228500e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>1.175505e+05</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>1.781445e+05</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>2.376420e+05</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>90.000000</td>\n",
       "      <td>1.490400e+06</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>4356.000000</td>\n",
       "      <td>99.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age        fnlwgt  education-num  capital-gain  capital-loss  \\\n",
       "count  48842.000000  4.884200e+04   48842.000000  48842.000000  48842.000000   \n",
       "mean      38.643585  1.896641e+05      10.078089   1079.067626     87.502314   \n",
       "std       13.710510  1.056040e+05       2.570973   7452.019058    403.004552   \n",
       "min       17.000000  1.228500e+04       1.000000      0.000000      0.000000   \n",
       "25%       28.000000  1.175505e+05       9.000000      0.000000      0.000000   \n",
       "50%       37.000000  1.781445e+05      10.000000      0.000000      0.000000   \n",
       "75%       48.000000  2.376420e+05      12.000000      0.000000      0.000000   \n",
       "max       90.000000  1.490400e+06      16.000000  99999.000000   4356.000000   \n",
       "\n",
       "       hours-per-week  \n",
       "count    48842.000000  \n",
       "mean        40.422382  \n",
       "std         12.391444  \n",
       "min          1.000000  \n",
       "25%         40.000000  \n",
       "50%         40.000000  \n",
       "75%         45.000000  \n",
       "max         99.000000  "
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cleaned.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "6520d361-de6c-47ec-a1fa-3de1134d06a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"C:\\Users\\pogoz\\anaconda3\\lib\\runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 460, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 367, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 662, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 360, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2914, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2960, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 78, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3185, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3377, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\pogoz\\AppData\\Local\\Temp\\ipykernel_18052\\1764139403.py\", line 1, in <module>\n",
      "    from sklearn.model_selection import train_test_split\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\sklearn\\__init__.py\", line 73, in <module>\n",
      "    from .base import clone  # noqa: E402\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 19, in <module>\n",
      "    from .utils._estimator_html_repr import _HTMLDocumentationLinkMixin, estimator_html_repr\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\sklearn\\utils\\__init__.py\", line 15, in <module>\n",
      "    from ._chunking import gen_batches, gen_even_slices\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_chunking.py\", line 11, in <module>\n",
      "    from ._param_validation import Interval, validate_params\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 14, in <module>\n",
      "    from scipy.sparse import csr_matrix, issparse\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\scipy\\sparse\\__init__.py\", line 228, in <module>\n",
      "    from .csr import *\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\scipy\\sparse\\csr.py\", line 10, in <module>\n",
      "    from ._sparsetools import (csr_tocsc, csr_tobsr, csr_count_blocks,\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core.multiarray failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18052\\1764139403.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# Check for any other potentially imbalanced categorical variables\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstring_columns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'income'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"\\n{column} distribution:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[0m_distributor_init\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m )\n\u001b[1;32m---> 73\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mclone\u001b[0m  \u001b[1;31m# noqa: E402\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_show_versions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mshow_versions\u001b[0m  \u001b[1;31m# noqa: E402\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_config\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInconsistentVersionWarning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_estimator_html_repr\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_HTMLDocumentationLinkMixin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimator_html_repr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_metadata_requests\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_MetadataRequester\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_routing_enabled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_param_validation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mvalidate_parameter_constraints\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_joblib\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetadata_routing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_bunch\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBunch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_chunking\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgen_batches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgen_even_slices\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_estimator_html_repr\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mestimator_html_repr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_chunking.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_config\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_param_validation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInterval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate_params\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcsr_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_config\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 228\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mcsr\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    229\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mcsc\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mlil\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\csr.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mspmatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m from ._sparsetools import (csr_tocsc, csr_tobsr, csr_count_blocks,\n\u001b[0m\u001b[0;32m     11\u001b[0m                            get_csr_submatrix)\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0msputils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mupcast\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_index_dtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: numpy.core.multiarray failed to import"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Check for any other potentially imbalanced categorical variables\n",
    "for column in string_columns:\n",
    "    if column != 'income':\n",
    "        print(f\"\\n{column} distribution:\")\n",
    "        print(data_cleaned[column].value_counts(normalize=True).head())\n",
    "\n",
    "# Perform train/test split with stratification on 'income'\n",
    "X = data_cleaned.drop('income', axis=1)\n",
    "y = data_cleaned['income']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Display the size of the train and test sets\n",
    "print(\"\\nTrain set size:\", len(X_train))\n",
    "print(\"Test set size:\", len(X_test))\n",
    "\n",
    "# Verify the stratification\n",
    "print(\"\\nIncome distribution in train set:\")\n",
    "print(y_train.value_counts(normalize=True))\n",
    "print(\"\\nIncome distribution in test set:\")\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "d2352eba-900a-4cc5-8011-6302752c1e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"C:\\Users\\pogoz\\anaconda3\\lib\\runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 460, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 367, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 662, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 360, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2914, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2960, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 78, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3185, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3377, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\pogoz\\AppData\\Local\\Temp\\ipykernel_18052\\2300559203.py\", line 2, in <module>\n",
      "    import matplotlib.pyplot as plt\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\matplotlib\\__init__.py\", line 109, in <module>\n",
      "    from . import _api, _version, cbook, docstring, rcsetup\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\matplotlib\\rcsetup.py\", line 27, in <module>\n",
      "    from matplotlib.colors import Colormap, is_color_like\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\matplotlib\\colors.py\", line 56, in <module>\n",
      "    from matplotlib import _api, cbook, scale\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\matplotlib\\scale.py\", line 23, in <module>\n",
      "    from matplotlib.ticker import (\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\matplotlib\\ticker.py\", line 136, in <module>\n",
      "    from matplotlib import transforms as mtransforms\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\matplotlib\\transforms.py\", line 46, in <module>\n",
      "    from matplotlib._path import (\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core.multiarray failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18052\\2300559203.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Visualize the distribution of age\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdata_cleaned\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'age'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[1;31m# cbook must import matplotlib only within function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[1;31m# definitions, so it is safe to import from it here.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_api\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_version\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdocstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrcsetup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcbook\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMatplotlibDeprecationWarning\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msanitize_sequence\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcbook\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmplDeprecation\u001b[0m  \u001b[1;31m# deprecated\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\rcsetup.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_api\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcbook\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mls_mapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolors\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mColormap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_color_like\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfontconfig_pattern\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mparse_fontconfig_pattern\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_enums\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mJoinStyle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCapStyle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\colors.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmpl\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_api\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_color_data\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBASE_COLORS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTABLEAU_COLORS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCSS4_COLORS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXKCD_COLORS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\scale.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmpl\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_api\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdocstring\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m from matplotlib.ticker import (\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[0mNullFormatter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mScalarFormatter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLogFormatterSciNotation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLogitFormatter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0mNullLocator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLogLocator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAutoLocator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAutoMinorLocator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\ticker.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmpl\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_api\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtransforms\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmtransforms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[0m_log\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetLogger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\transforms.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_api\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m from matplotlib._path import (\n\u001b[0m\u001b[0;32m     47\u001b[0m     affine_transform, count_bboxes_overlapping_bbox, update_path_extents)\n\u001b[0;32m     48\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: numpy.core.multiarray failed to import"
     ]
    }
   ],
   "source": [
    "# Visualize the distribution of age\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "data_cleaned['age'].hist(bins=20)\n",
    "plt.title('Distribution of Age')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "06db6782-a711-46c7-bb8c-56b8327e319d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"C:\\Users\\pogoz\\anaconda3\\lib\\runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 460, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 367, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 662, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 360, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2914, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2960, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 78, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3185, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3377, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\pogoz\\AppData\\Local\\Temp\\ipykernel_18052\\1473603675.py\", line 1, in <module>\n",
      "    import matplotlib.pyplot as plt\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\matplotlib\\__init__.py\", line 109, in <module>\n",
      "    from . import _api, _version, cbook, docstring, rcsetup\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\matplotlib\\rcsetup.py\", line 27, in <module>\n",
      "    from matplotlib.colors import Colormap, is_color_like\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\matplotlib\\colors.py\", line 56, in <module>\n",
      "    from matplotlib import _api, cbook, scale\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\matplotlib\\scale.py\", line 23, in <module>\n",
      "    from matplotlib.ticker import (\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\matplotlib\\ticker.py\", line 136, in <module>\n",
      "    from matplotlib import transforms as mtransforms\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\matplotlib\\transforms.py\", line 46, in <module>\n",
      "    from matplotlib._path import (\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core.multiarray failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18052\\1473603675.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Generate histograms for all numeric columns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mnumeric_columns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'age'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fnlwgt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'education-num'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'capital-gain'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'capital-loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'hours-per-week'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdata_cleaned\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnumeric_columns\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[1;31m# cbook must import matplotlib only within function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[1;31m# definitions, so it is safe to import from it here.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_api\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_version\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdocstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrcsetup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcbook\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMatplotlibDeprecationWarning\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msanitize_sequence\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcbook\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmplDeprecation\u001b[0m  \u001b[1;31m# deprecated\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\rcsetup.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_api\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcbook\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mls_mapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolors\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mColormap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_color_like\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfontconfig_pattern\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mparse_fontconfig_pattern\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_enums\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mJoinStyle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCapStyle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\colors.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmpl\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_api\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_color_data\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBASE_COLORS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTABLEAU_COLORS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCSS4_COLORS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXKCD_COLORS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\scale.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmpl\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_api\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdocstring\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m from matplotlib.ticker import (\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[0mNullFormatter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mScalarFormatter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLogFormatterSciNotation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLogitFormatter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0mNullLocator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLogLocator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAutoLocator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAutoMinorLocator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\ticker.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmpl\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_api\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtransforms\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmtransforms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[0m_log\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetLogger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\transforms.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_api\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m from matplotlib._path import (\n\u001b[0m\u001b[0;32m     47\u001b[0m     affine_transform, count_bboxes_overlapping_bbox, update_path_extents)\n\u001b[0;32m     48\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: numpy.core.multiarray failed to import"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate histograms for all numeric columns\n",
    "numeric_columns = ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "data_cleaned[numeric_columns].hist(bins=50, figsize=(12, 8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "7e0cc8f7-ad5b-4a04-9167-af088264683c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ydata_profiling'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18052\\1066738395.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mydata_profiling\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mProfileReport\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Create a sample DataFrame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'ydata_profiling'"
     ]
    }
   ],
   "source": [
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "# Create a sample DataFrame\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.DataFrame(np.random.rand(100, 5), columns=[\"a\", \"b\", \"c\", \"d\", \"e\"])\n",
    "\n",
    "# Generate the report\n",
    "profile = ProfileReport(df, title=\"Profiling Report\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "74616fb8-4a2d-45f4-8f12-aa33462d103c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ydata-profiling is not installed\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import ydata_profiling\n",
    "    print(\"ydata-profiling is successfully installed\")\n",
    "except ModuleNotFoundError:\n",
    "    print(\"ydata-profiling is not installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "5ee98009-1114-4d39-bd95-5613c57b259b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"C:\\Users\\pogoz\\anaconda3\\lib\\runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 460, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 367, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 662, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 360, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2914, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2960, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 78, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3185, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3377, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\pogoz\\AppData\\Local\\Temp\\ipykernel_18052\\1381914357.py\", line 1, in <module>\n",
      "    import seaborn as sns\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\seaborn\\__init__.py\", line 2, in <module>\n",
      "    from .rcmod import *  # noqa: F401,F403\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\seaborn\\rcmod.py\", line 5, in <module>\n",
      "    import matplotlib as mpl\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\matplotlib\\__init__.py\", line 109, in <module>\n",
      "    from . import _api, _version, cbook, docstring, rcsetup\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\matplotlib\\rcsetup.py\", line 27, in <module>\n",
      "    from matplotlib.colors import Colormap, is_color_like\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\matplotlib\\colors.py\", line 56, in <module>\n",
      "    from matplotlib import _api, cbook, scale\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\matplotlib\\scale.py\", line 23, in <module>\n",
      "    from matplotlib.ticker import (\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\matplotlib\\ticker.py\", line 136, in <module>\n",
      "    from matplotlib import transforms as mtransforms\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\matplotlib\\transforms.py\", line 46, in <module>\n",
      "    from matplotlib._path import (\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core.multiarray failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18052\\1381914357.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# Visualize the correlation matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mcorrelation_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_cleaned\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorrelation_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mannot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'coolwarm'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\seaborn\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Import seaborn objects\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mrcmod\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m  \u001b[1;31m# noqa: F401,F403\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m  \u001b[1;31m# noqa: F401,F403\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mpalettes\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m  \u001b[1;31m# noqa: F401,F403\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mrelational\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m  \u001b[1;31m# noqa: F401,F403\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\seaborn\\rcmod.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfunctools\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdistutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLooseVersion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmpl\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcycler\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcycler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpalettes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[1;31m# cbook must import matplotlib only within function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[1;31m# definitions, so it is safe to import from it here.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_api\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_version\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdocstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrcsetup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcbook\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMatplotlibDeprecationWarning\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msanitize_sequence\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcbook\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmplDeprecation\u001b[0m  \u001b[1;31m# deprecated\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\rcsetup.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_api\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcbook\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mls_mapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolors\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mColormap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_color_like\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfontconfig_pattern\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mparse_fontconfig_pattern\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_enums\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mJoinStyle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCapStyle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\colors.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmpl\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_api\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_color_data\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBASE_COLORS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTABLEAU_COLORS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCSS4_COLORS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXKCD_COLORS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\scale.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmpl\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_api\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdocstring\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m from matplotlib.ticker import (\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[0mNullFormatter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mScalarFormatter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLogFormatterSciNotation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLogitFormatter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0mNullLocator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLogLocator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAutoLocator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAutoMinorLocator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\ticker.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmpl\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_api\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtransforms\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmtransforms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[0m_log\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetLogger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\transforms.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_api\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m from matplotlib._path import (\n\u001b[0m\u001b[0;32m     47\u001b[0m     affine_transform, count_bboxes_overlapping_bbox, update_path_extents)\n\u001b[0;32m     48\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: numpy.core.multiarray failed to import"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "# Visualize the correlation matrix\n",
    "correlation_matrix = data_cleaned.corr()\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "plt.title(\"Correlation Matrix of Numeric Features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "512915a2-74af-420a-a40d-e931a0d382ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"C:\\Users\\pogoz\\anaconda3\\lib\\runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 460, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 367, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 662, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 360, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2914, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2960, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 78, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3185, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3377, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\pogoz\\AppData\\Local\\Temp\\ipykernel_18052\\3485194691.py\", line 1, in <module>\n",
      "    import mlflow\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\mlflow\\__init__.py\", line 35, in <module>\n",
      "    from mlflow import (\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\mlflow\\data\\__init__.py\", line 5, in <module>\n",
      "    from mlflow.data import dataset_registry\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\mlflow\\data\\dataset_registry.py\", line 137, in <module>\n",
      "    from mlflow.data.pandas_dataset import from_pandas\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\mlflow\\data\\pandas_dataset.py\", line 12, in <module>\n",
      "    from mlflow.data.pyfunc_dataset_mixin import PyFuncConvertibleDatasetMixin, PyFuncInputsOutputs\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\mlflow\\data\\pyfunc_dataset_mixin.py\", line 6, in <module>\n",
      "    from mlflow.models.utils import PyFuncInput, PyFuncOutput\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\mlflow\\models\\__init__.py\", line 77, in <module>\n",
      "    from mlflow.models.signature import ModelSignature, infer_signature, set_signature\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\mlflow\\models\\signature.py\", line 22, in <module>\n",
      "    from mlflow.models.utils import _contains_params, _Example\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\mlflow\\models\\utils.py\", line 46, in <module>\n",
      "    from scipy.sparse import csc_matrix, csr_matrix\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\scipy\\sparse\\__init__.py\", line 228, in <module>\n",
      "    from .csr import *\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\scipy\\sparse\\csr.py\", line 10, in <module>\n",
      "    from ._sparsetools import (csr_tocsc, csr_tobsr, csr_count_blocks,\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///C:/Users/pogoz/EAS503%20Final/mlruns/652044503664654552', creation_time=1734727916986, experiment_id='652044503664654552', last_update_time=1734727916986, lifecycle_stage='active', name='Adult Income Classification', tags={}>"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "# Create the experiment if it doesn't exist\n",
    "experiment_name = \"Adult Income Classification\"\n",
    "try:\n",
    "    experiment_id = mlflow.create_experiment(experiment_name)\n",
    "except mlflow.exceptions.MlflowException:\n",
    "    experiment_id = mlflow.get_experiment_by_name(experiment_name).experiment_id\n",
    "\n",
    "# Set the experiment as active\n",
    "mlflow.set_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "c4e258bf-1565-4acb-a57c-386cbaf86289",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"C:\\Users\\pogoz\\anaconda3\\lib\\runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 460, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 367, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 662, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 360, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2914, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2960, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 78, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3185, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3377, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\pogoz\\AppData\\Local\\Temp\\ipykernel_18052\\1692445245.py\", line 3, in <module>\n",
      "    from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\sklearn\\__init__.py\", line 73, in <module>\n",
      "    from .base import clone  # noqa: E402\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 19, in <module>\n",
      "    from .utils._estimator_html_repr import _HTMLDocumentationLinkMixin, estimator_html_repr\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\sklearn\\utils\\__init__.py\", line 15, in <module>\n",
      "    from ._chunking import gen_batches, gen_even_slices\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_chunking.py\", line 11, in <module>\n",
      "    from ._param_validation import Interval, validate_params\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 14, in <module>\n",
      "    from scipy.sparse import csr_matrix, issparse\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\scipy\\sparse\\__init__.py\", line 228, in <module>\n",
      "    from .csr import *\n",
      "  File \"C:\\Users\\pogoz\\anaconda3\\lib\\site-packages\\scipy\\sparse\\csr.py\", line 10, in <module>\n",
      "    from ._sparsetools import (csr_tocsc, csr_tobsr, csr_count_blocks,\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core.multiarray failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18052\\1692445245.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimpute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSimpleImputer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mOneHotEncoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFunctionTransformer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[0m_distributor_init\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m )\n\u001b[1;32m---> 73\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mclone\u001b[0m  \u001b[1;31m# noqa: E402\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_show_versions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mshow_versions\u001b[0m  \u001b[1;31m# noqa: E402\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_config\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInconsistentVersionWarning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_estimator_html_repr\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_HTMLDocumentationLinkMixin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimator_html_repr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_metadata_requests\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_MetadataRequester\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_routing_enabled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_param_validation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mvalidate_parameter_constraints\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_joblib\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetadata_routing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_bunch\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBunch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_chunking\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgen_batches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgen_even_slices\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_estimator_html_repr\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mestimator_html_repr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_chunking.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_config\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_param_validation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInterval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate_params\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcsr_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_config\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 228\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mcsr\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    229\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mcsc\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mlil\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\csr.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mspmatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m from ._sparsetools import (csr_tocsc, csr_tobsr, csr_count_blocks,\n\u001b[0m\u001b[0;32m     11\u001b[0m                            get_csr_submatrix)\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0msputils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mupcast\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_index_dtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: numpy.core.multiarray failed to import"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import dagshub\n",
    "dagshub.init(repo_owner='kobekim27', repo_name='EAS503', mlflow=True)\n",
    "# Assuming 'data_cleaned' is your final DataFrame and 'income' is the target\n",
    "print(\"Target distribution in the whole dataset:\")\n",
    "print(data_cleaned['income'].value_counts(normalize=True))\n",
    "\n",
    "X = data_cleaned.drop('income', axis=1)\n",
    "y = data_cleaned['income']\n",
    "\n",
    "# Stratify by the target\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "print(\"\\nTrain set 'income' distribution:\")\n",
    "print(y_train.value_counts(normalize=True))\n",
    "print(\"\\nTest set 'income' distribution:\")\n",
    "print(y_test.value_counts(normalize=True))\n",
    "\n",
    "# Identify numeric & categorical features\n",
    "numeric_features = ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "categorical_features = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n",
    "\n",
    "# Log transform for 'capital-gain' and 'capital-loss' if skewed\n",
    "def log_transform_capital(X):\n",
    "    X = X.copy()\n",
    "    for feature in ['capital-gain', 'capital-loss']:\n",
    "        idx = numeric_features.index(feature)\n",
    "        X[:, idx] = np.log1p(X[:, idx])\n",
    "    return X\n",
    "\n",
    "log_transformer = FunctionTransformer(log_transform_capital, validate=False)\n",
    "\n",
    "# Preprocessing pipelines\n",
    "numeric_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"log_transform\", log_transformer),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocessing = ColumnTransformer([\n",
    "    (\"num\", numeric_pipeline, numeric_features),\n",
    "    (\"cat\", categorical_pipeline, categorical_features)\n",
    "])\n",
    "\n",
    "# Base model: Logistic Regression\n",
    "model = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"preprocessing\", preprocessing),\n",
    "    (\"clf\", model)\n",
    "])\n",
    "\n",
    "# Hyperparameter tuning with GridSearchCV\n",
    "param_grid = {\n",
    "    \"clf__C\": [0.01, 0.1, 1, 10],\n",
    "    \"clf__penalty\": [\"l2\"]\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "grid_search = GridSearchCV(pipeline, param_grid, scoring='f1', cv=cv, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "cv_results = grid_search.cv_results_\n",
    "mean_f1 = grid_search.best_score_\n",
    "std_f1 = cv_results['std_test_score'][grid_search.best_index_]\n",
    "\n",
    "print(\"\\nBest Params:\", grid_search.best_params_)\n",
    "print(\"CV Mean F1:\", mean_f1, \"CV Std F1:\", std_f1)\n",
    "\n",
    "# Evaluate on Training and Test sets\n",
    "y_pred_train = best_model.predict(X_train)\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "\n",
    "f1_train = f1_score(y_train, y_pred_train, average='weighted')\n",
    "f1_test = f1_score(y_test, y_pred_test, average='weighted')\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_test)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "print(\"\\nTrain F1:\", f1_train)\n",
    "print(\"Test F1:\", f1_test)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "# Log results to MLflow (DagsHub)\n",
    "MLFLOW_TRACKING_URI = \"https://dagshub.com/kobekim27/EAS503.mlflow\"\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "mlflow.set_experiment(\"Adult_Income_Experiment1\")\n",
    "\n",
    "from mlflow.models import infer_signature\n",
    "signature = infer_signature(X_train, best_model.predict(X_train))\n",
    "\n",
    "with mlflow.start_run():\n",
    "    # Log hyperparameters\n",
    "    mlflow.log_params(grid_search.best_params_)\n",
    "\n",
    "    # Log CV results\n",
    "    mlflow.log_metric(\"cv_mean_f1\", mean_f1)\n",
    "    mlflow.log_metric(\"cv_std_f1\", std_f1)\n",
    "\n",
    "    # Log train/test metrics\n",
    "    mlflow.log_metric(\"f1_train\", f1_train)\n",
    "    mlflow.log_metric(\"f1_test\", f1_test)\n",
    "\n",
    "    # Log confusion matrix elements\n",
    "    mlflow.log_metric(\"tn\", tn)\n",
    "    mlflow.log_metric(\"fp\", fp)\n",
    "    mlflow.log_metric(\"fn\", fn)\n",
    "    mlflow.log_metric(\"tp\", tp)\n",
    "\n",
    "    # Log the model\n",
    "    mlflow.sklearn.log_model(best_model, \"best_model\", signature=signature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a565f8d4-e826-4c3c-a58d-814aa0fa0ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, FunctionTransformer, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "# Assuming 'data_cleaned' is your final DataFrame and 'income' is the target\n",
    "X = data_cleaned.drop('income', axis=1)\n",
    "y = data_cleaned['income']\n",
    "\n",
    "# Encode the target variable\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# Stratify by the target\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Identify numeric & categorical features\n",
    "numeric_features = ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "categorical_features = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n",
    "\n",
    "# Log transform for 'capital-gain' and 'capital-loss' if skewed\n",
    "def log_transform_capital(X):\n",
    "    X = X.copy()\n",
    "    for feature in ['capital-gain', 'capital-loss']:\n",
    "        idx = numeric_features.index(feature)\n",
    "        X[:, idx] = np.log1p(X[:, idx])\n",
    "    return X\n",
    "\n",
    "log_transformer = FunctionTransformer(log_transform_capital, validate=False)\n",
    "\n",
    "# Preprocessing pipelines\n",
    "numeric_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"log_transform\", log_transformer),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocessing = ColumnTransformer([\n",
    "    (\"num\", numeric_pipeline, numeric_features),\n",
    "    (\"cat\", categorical_pipeline, categorical_features)\n",
    "])\n",
    "\n",
    "# Define classifiers\n",
    "classifiers = {\n",
    "    'LogisticRegression': LogisticRegression(solver='lbfgs', max_iter=1000),\n",
    "    'RidgeClassifier': RidgeClassifier(),\n",
    "    'RandomForestClassifier': RandomForestClassifier(),\n",
    "    'XGBClassifier': XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "}\n",
    "\n",
    "# Hyperparameter grids for each classifier\n",
    "param_grids = {\n",
    "    'LogisticRegression': {'clf__C': [0.01, 0.1, 1, 10], 'clf__penalty': ['l2']},\n",
    "    'RidgeClassifier': {'clf__alpha': [0.1, 1.0, 10.0]},\n",
    "    'RandomForestClassifier': {'clf__n_estimators': [100, 200], 'clf__max_depth': [5, 10]},\n",
    "    'XGBClassifier': {'clf__learning_rate': [0.01, 0.1], 'clf__n_estimators': [100, 200]}\n",
    "}\n",
    "\n",
    "# Set up MLflow\n",
    "MLFLOW_TRACKING_URI = \"https://dagshub.com/kobekim27/EAS503.mlflow\"\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "mlflow.set_experiment(\"Adult_Income_Experiment2\")\n",
    "\n",
    "# Train and evaluate each classifier\n",
    "for clf_name, clf in classifiers.items():\n",
    "    with mlflow.start_run(run_name=clf_name):\n",
    "        pipeline = Pipeline([\n",
    "            (\"preprocessing\", preprocessing),\n",
    "            (\"clf\", clf)\n",
    "        ])\n",
    "\n",
    "        cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "        grid_search = GridSearchCV(pipeline, param_grids[clf_name], scoring='f1', cv=cv, n_jobs=-1)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "\n",
    "        best_model = grid_search.best_estimator_\n",
    "        cv_results = grid_search.cv_results_\n",
    "        mean_f1 = grid_search.best_score_\n",
    "        std_f1 = cv_results['std_test_score'][grid_search.best_index_]\n",
    "\n",
    "        # Evaluate on Training and Test sets\n",
    "        y_pred_train = best_model.predict(X_train)\n",
    "        y_pred_test = best_model.predict(X_test)\n",
    "\n",
    "        f1_train = f1_score(y_train, y_pred_train, average='weighted')\n",
    "        f1_test = f1_score(y_test, y_pred_test, average='weighted')\n",
    "\n",
    "        cm = confusion_matrix(y_test, y_pred_test)\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "        # Log results to MLflow\n",
    "        mlflow.log_params(grid_search.best_params_)\n",
    "        mlflow.log_metric(\"cv_mean_f1\", mean_f1)\n",
    "        mlflow.log_metric(\"cv_std_f1\", std_f1)\n",
    "        mlflow.log_metric(\"f1_train\", f1_train)\n",
    "        mlflow.log_metric(\"f1_test\", f1_test)\n",
    "        mlflow.log_metric(\"tn\", tn)\n",
    "        mlflow.log_metric(\"fp\", fp)\n",
    "        mlflow.log_metric(\"fn\", fn)\n",
    "        mlflow.log_metric(\"tp\", tp)\n",
    "\n",
    "        # Log the model\n",
    "        signature = mlflow.models.infer_signature(X_train, best_model.predict(X_train))\n",
    "        mlflow.sklearn.log_model(best_model, \"best_model\", signature=signature)\n",
    "\n",
    "        print(f\"\\nResults for {clf_name}:\")\n",
    "        print(\"Best Params:\", grid_search.best_params_)\n",
    "        print(\"CV Mean F1:\", mean_f1, \"CV Std F1:\", std_f1)\n",
    "        print(\"Train F1:\", f1_train)\n",
    "        print(\"Test F1:\", f1_test)\n",
    "        print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "# If you need to convert predictions back to original labels\n",
    "# y_pred_original = le.inverse_transform(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c206de98-4303-493c-a1ae-b0da4b69e3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import dagshub\n",
    "\n",
    "# Initialize DagsHub\n",
    "dagshub.init(repo_owner='kobekim27', repo_name='EAS503', mlflow=True)\n",
    "\n",
    "# Assuming 'data_cleaned' is your final DataFrame and 'income' is the target\n",
    "X = data_cleaned.drop('income', axis=1)\n",
    "y = data_cleaned['income']\n",
    "\n",
    "# Encode the target variable\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# Feature Engineering\n",
    "def engineer_features(X):\n",
    "    X = X.copy()\n",
    "    \n",
    "    # Combine education-num and hours-per-week\n",
    "    X['education_work_intensity'] = X['education-num'] * X['hours-per-week']\n",
    "    \n",
    "    # Create age groups\n",
    "    X['age_group'] = pd.cut(X['age'], bins=[0, 25, 35, 45, 55, 65, 100], labels=['0-25', '26-35', '36-45', '46-55', '56-65', '65+'])\n",
    "    \n",
    "    # Combine capital-gain and capital-loss\n",
    "    X['net_capital'] = X['capital-gain'] - X['capital-loss']\n",
    "    \n",
    "    # Create a feature for total work experience\n",
    "    X['work_experience'] = X['age'] - X['education-num'] - 6\n",
    "    X['work_experience'] = X['work_experience'].clip(lower=0)\n",
    "    \n",
    "    # Interaction between age and education-num\n",
    "    X['age_education_interaction'] = X['age'] * X['education-num']\n",
    "    \n",
    "    return X\n",
    "\n",
    "X = engineer_features(X)\n",
    "\n",
    "# Update feature lists\n",
    "numeric_features = ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week', \n",
    "                    'education_work_intensity', 'net_capital', 'work_experience', 'age_education_interaction']\n",
    "categorical_features = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country', 'age_group']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Preprocessing pipelines\n",
    "numeric_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocessing = ColumnTransformer([\n",
    "    (\"num\", numeric_pipeline, numeric_features),\n",
    "    (\"cat\", categorical_pipeline, categorical_features)\n",
    "])\n",
    "\n",
    "# Define classifiers\n",
    "classifiers = {\n",
    "    'LogisticRegression': LogisticRegression(solver='lbfgs', max_iter=1000),\n",
    "    'RidgeClassifier': RidgeClassifier(),\n",
    "    'RandomForestClassifier': RandomForestClassifier(),\n",
    "    'XGBClassifier': XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "}\n",
    "\n",
    "# Hyperparameter grids\n",
    "param_grids = {\n",
    "    'LogisticRegression': {'clf__C': [0.01, 0.1, 1, 10], 'clf__penalty': ['l2']},\n",
    "    'RidgeClassifier': {'clf__alpha': [0.1, 1.0, 10.0]},\n",
    "    'RandomForestClassifier': {'clf__n_estimators': [100, 200], 'clf__max_depth': [5, 10, None]},\n",
    "    'XGBClassifier': {'clf__learning_rate': [0.01, 0.1], 'clf__n_estimators': [100, 200], 'clf__max_depth': [3, 5, 7]}\n",
    "}\n",
    "\n",
    "# Set up MLflow\n",
    "MLFLOW_TRACKING_URI = \"https://dagshub.com/kobekim27/EAS503.mlflow\"\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "mlflow.set_experiment(\"Adult_Income_Experiment3\")\n",
    "\n",
    "# Train and evaluate each classifier\n",
    "for clf_name, clf in classifiers.items():\n",
    "    with mlflow.start_run(run_name=f\"{clf_name}_FeatureEngineering\"):\n",
    "        pipeline = Pipeline([\n",
    "            (\"preprocessing\", preprocessing),\n",
    "            (\"clf\", clf)\n",
    "        ])\n",
    "\n",
    "        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        grid_search = GridSearchCV(pipeline, param_grids[clf_name], scoring='f1', cv=cv, n_jobs=-1)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "\n",
    "        best_model = grid_search.best_estimator_\n",
    "        cv_results = grid_search.cv_results_\n",
    "        mean_f1 = grid_search.best_score_\n",
    "        std_f1 = cv_results['std_test_score'][grid_search.best_index_]\n",
    "\n",
    "        # Evaluate on Training and Test sets\n",
    "        y_pred_train = best_model.predict(X_train)\n",
    "        y_pred_test = best_model.predict(X_test)\n",
    "\n",
    "        f1_train = f1_score(y_train, y_pred_train, average='weighted')\n",
    "        f1_test = f1_score(y_test, y_pred_test, average='weighted')\n",
    "\n",
    "        cm = confusion_matrix(y_test, y_pred_test)\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "        # Log results to MLflow\n",
    "        mlflow.log_params(grid_search.best_params_)\n",
    "        mlflow.log_metric(\"cv_mean_f1\", mean_f1)\n",
    "        mlflow.log_metric(\"cv_std_f1\", std_f1)\n",
    "        mlflow.log_metric(\"f1_train\", f1_train)\n",
    "        mlflow.log_metric(\"f1_test\", f1_test)\n",
    "        mlflow.log_metric(\"tn\", tn)\n",
    "        mlflow.log_metric(\"fp\", fp)\n",
    "        mlflow.log_metric(\"fn\", fn)\n",
    "        mlflow.log_metric(\"tp\", tp)\n",
    "\n",
    "        # Log the model\n",
    "        signature = mlflow.models.infer_signature(X_train, best_model.predict(X_train))\n",
    "        mlflow.sklearn.log_model(best_model, \"best_model\", signature=signature)\n",
    "\n",
    "        print(f\"\\nResults for {clf_name}:\")\n",
    "        print(\"Best Params:\", grid_search.best_params_)\n",
    "        print(\"CV Mean F1:\", mean_f1, \"CV Std F1:\", std_f1)\n",
    "        print(\"Train F1:\", f1_train)\n",
    "        print(\"Test F1:\", f1_test)\n",
    "        print(\"Confusion Matrix:\\n\", cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46642948-f47a-432d-825d-a432a9b7a98a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest, f_classif\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import dagshub\n",
    "\n",
    "# Initialize DagsHub\n",
    "dagshub.init(repo_owner='kobekim27', repo_name='EAS503', mlflow=True)\n",
    "\n",
    "# Assuming 'data_cleaned' is your final DataFrame and 'income' is the target\n",
    "X = data_cleaned.drop('income', axis=1)\n",
    "y = data_cleaned['income']\n",
    "\n",
    "# Identify numeric and categorical columns\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Set up MLflow\n",
    "MLFLOW_TRACKING_URI = \"https://dagshub.com/kobekim27/EAS503.mlflow\"\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "mlflow.set_experiment(\"Adult_Income_Experiment4\")\n",
    "\n",
    "# Feature Selection Methods\n",
    "def correlation_threshold(x, threshold=0.8):\n",
    "    corr_matrix = x.corr()\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "    return [col for col in x.columns if col not in to_drop]\n",
    "\n",
    "\n",
    "def feature_importance(X, y, threshold=0.01):\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf.fit(X, y)\n",
    "    importances = pd.Series(rf.feature_importances_, index=X.columns)\n",
    "    return X[importances[importances > threshold].index]\n",
    "\n",
    "# Preprocessing\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='median')),\n",
    "            ('scaler', StandardScaler())\n",
    "        ]), numeric_features),\n",
    "        ('cat', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "            ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "        ]), categorical_features)\n",
    "    ])\n",
    "\n",
    "# Feature Selection Pipelines\n",
    "pipelines = {\n",
    "    'Correlation_Threshold': Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('correlation', FunctionTransformer(correlation_threshold, kw_args={'threshold': 0.8})),\n",
    "        ('selector', FunctionTransformer(lambda X, columns: X[columns])),\n",
    "        ('clf', RandomForestClassifier(random_state=42))\n",
    "    ]),\n",
    "    'Feature_Importance': Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('importance', FunctionTransformer(feature_importance, kw_args={'threshold': 0.01})),\n",
    "        ('clf', RandomForestClassifier(random_state=42))\n",
    "    ]),\n",
    "    'Variance_Threshold': Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('variance', VarianceThreshold(threshold=0.1)),\n",
    "        ('clf', RandomForestClassifier(random_state=42))\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Train and evaluate each pipeline\n",
    "for name, pipeline in pipelines.items():\n",
    "    with mlflow.start_run(run_name=f\"{name}_FeatureSelection\"):\n",
    "        # Fit the pipeline\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        \n",
    "        # Get selected features\n",
    "        if name == 'Correlation_Threshold':\n",
    "            selected_features = pipeline.named_steps['correlation'].get_feature_names_out()\n",
    "        elif name == 'Feature_Importance':\n",
    "            selected_features = pipeline.named_steps['importance'].get_feature_names_out()\n",
    "        else:  # Variance_Threshold\n",
    "            selected_features = pipeline.named_steps['variance'].get_feature_names_out()\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred_train = pipeline.predict(X_train)\n",
    "        y_pred_test = pipeline.predict(X_test)\n",
    "        \n",
    "        # Calculate F1 scores\n",
    "        f1_train = f1_score(y_train, y_pred_train, average='weighted')\n",
    "        f1_test = f1_score(y_test, y_pred_test, average='weighted')\n",
    "        \n",
    "        # Log results to MLflow\n",
    "        mlflow.log_param(\"num_selected_features\", len(selected_features))\n",
    "        mlflow.log_param(\"selected_features\", \", \".join(selected_features))\n",
    "        mlflow.log_metric(\"f1_train\", f1_train)\n",
    "        mlflow.log_metric(\"f1_test\", f1_test)\n",
    "        \n",
    "        # Log the model\n",
    "        mlflow.sklearn.log_model(pipeline, \"model\")\n",
    "        \n",
    "        print(f\"Feature Selection Method: {name}\")\n",
    "        print(f\"Number of selected features: {len(selected_features)}\")\n",
    "        print(f\"F1 Score (Train): {f1_train:.4f}\")\n",
    "        print(f\"F1 Score (Test): {f1_test:.4f}\")\n",
    "        print(\"Selected features:\", \", \".join(selected_features))\n",
    "        print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fd6923-3608-4be3-9cca-e80966cca1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Initialize DagsHub\n",
    "dagshub.init(repo_owner='kobekim27', repo_name='EAS503', mlflow=True)\n",
    "# Assuming 'data_cleaned' is your final DataFrame and 'income' is the target\n",
    "X = data_cleaned.drop('income', axis=1)\n",
    "y = data_cleaned['income']\n",
    "\n",
    "# Encode the target variable\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "# Assuming X and y are already defined\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "# Perform PCA\n",
    "pca = PCA()\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "\n",
    "# Create scree plot\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "cumulative_variance_ratio = np.cumsum(explained_variance_ratio)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(1, len(explained_variance_ratio) + 1), explained_variance_ratio)\n",
    "plt.plot(range(1, len(cumulative_variance_ratio) + 1), cumulative_variance_ratio, 'r-')\n",
    "plt.xlabel('Principal Components')\n",
    "plt.ylabel('Explained Variance Ratio')\n",
    "plt.title('Scree Plot')\n",
    "plt.savefig('scree_plot.png')\n",
    "plt.close()\n",
    "\n",
    "# Select number of components based on cumulative explained variance\n",
    "n_components = np.argmax(cumulative_variance_ratio >= 0.95) + 1\n",
    "\n",
    "# Apply PCA with selected number of components\n",
    "pca_final = PCA(n_components=n_components)\n",
    "X_train_pca_final = pca_final.fit_transform(X_train_scaled)\n",
    "X_test_pca_final = pca_final.transform(X_test_scaled)\n",
    "\n",
    "# Train Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "rf_classifier.fit(X_train_pca_final, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_train = rf_classifier.predict(X_train_pca_final)\n",
    "y_pred_test = rf_classifier.predict(X_test_pca_final)\n",
    "\n",
    "# Calculate F1 scores\n",
    "f1_train = f1_score(y_train, y_pred_train, average='weighted')\n",
    "f1_test = f1_score(y_test, y_pred_test, average='weighted')\n",
    "\n",
    "# Log results with MLflow\n",
    "with mlflow.start_run(run_name=\"Experiment_5_PCA\"):\n",
    "    mlflow.log_param(\"n_components\", n_components)\n",
    "    mlflow.log_metric(\"f1_train\", f1_train)\n",
    "    mlflow.log_metric(\"f1_test\", f1_test)\n",
    "    mlflow.log_artifact(\"scree_plot.png\")\n",
    "    mlflow.sklearn.log_model(rf_classifier, \"model\")\n",
    "    \n",
    "    print(f\"Number of selected components: {n_components}\")\n",
    "    print(f\"F1 Score (Train): {f1_train:.4f}\")\n",
    "    print(f\"F1 Score (Test): {f1_test:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07df1fa8-1824-44b5-a2c1-52cc2f3c4766",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming 'data_cleaned' is your final DataFrame and 'income' is the target\n",
    "X = data_cleaned.drop('income', axis=1)\n",
    "y = data_cleaned['income']\n",
    "\n",
    "# Encode the target variable\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "\n",
    "# Assuming X and y are already defined\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train initial Random Forest model\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get feature importances\n",
    "importances = rf.feature_importances_\n",
    "feature_importances = pd.Series(importances, index=X.columns).sort_values(ascending=False)\n",
    "\n",
    "with mlflow.start_run(run_name=\"Experiment_6_Feature_Importance\"):\n",
    "    # Log feature importances\n",
    "    for feature, importance in feature_importances.items():\n",
    "        mlflow.log_metric(f\"importance_{feature}\", importance)\n",
    "    \n",
    "    # Plot feature importances\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    feature_importances.plot(kind='bar')\n",
    "    plt.title('Feature Importances')\n",
    "    plt.xlabel('Features')\n",
    "    plt.ylabel('Importance')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('feature_importances.png')\n",
    "    mlflow.log_artifact('feature_importances.png')\n",
    "    plt.close()\n",
    "\n",
    "    # Train models with different numbers of top features\n",
    "    top_feature_counts = [5, 10, 15, 20, len(X.columns)]\n",
    "    for n_features in top_feature_counts:\n",
    "        top_features = feature_importances.index[:n_features]\n",
    "        X_train_top = X_train_scaled[:, X.columns.get_indexer(top_features)]\n",
    "        X_test_top = X_test_scaled[:, X.columns.get_indexer(top_features)]\n",
    "\n",
    "        rf_top = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "        rf_top.fit(X_train_top, y_train)\n",
    "\n",
    "        y_pred_train = rf_top.predict(X_train_top)\n",
    "        y_pred_test = rf_top.predict(X_test_top)\n",
    "\n",
    "        f1_train = f1_score(y_train, y_pred_train, average='weighted')\n",
    "        f1_test = f1_score(y_test, y_pred_test, average='weighted')\n",
    "\n",
    "        mlflow.log_param(f\"n_top_features\", n_features)\n",
    "        mlflow.log_metric(f\"f1_train_{n_features}\", f1_train)\n",
    "        mlflow.log_metric(f\"f1_test_{n_features}\", f1_test)\n",
    "\n",
    "        print(f\"Top {n_features} features:\")\n",
    "        print(f\"F1 Score (Train): {f1_train:.4f}\")\n",
    "        print(f\"F1 Score (Test): {f1_test:.4f}\")\n",
    "        print()\n",
    "\n",
    "    # Log the best model\n",
    "    best_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    best_model.fit(X_train_scaled, y_train)\n",
    "    mlflow.sklearn.log_model(best_model, \"best_model\")\n",
    "\n",
    "print(\"Experiment 6 completed and logged to MLflow\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "56bb5fcd-201c-42ec-9ac0-0a10f2e3f5c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping Education: Low, Hours: Part-time due to insufficient samples\n",
      "Skipping Education: Low, Hours: Full-time due to insufficient samples\n",
      "Skipping Education: Low, Hours: Overtime due to insufficient samples\n",
      "Skipping Education: Medium, Hours: Part-time due to insufficient samples\n",
      "Skipping Education: Medium, Hours: Full-time due to insufficient samples\n",
      "Skipping Education: Medium, Hours: Overtime due to insufficient samples\n",
      "Skipping Education: High, Hours: Part-time due to insufficient samples\n",
      "Skipping Education: High, Hours: Full-time due to insufficient samples\n",
      "Skipping Education: High, Hours: Overtime due to insufficient samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/20 19:07:31 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " View run Experiment_7_Education_Hours_Analysis at: https://dagshub.com/kobekim27/EAS503.mlflow/#/experiments/4/runs/fb49c66bc6724707ae04faf72f5cddce\n",
      " View experiment at: https://dagshub.com/kobekim27/EAS503.mlflow/#/experiments/4\n",
      "Experiment 7 completed and logged to MLflow\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming X and y are already defined as in your original code\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Simplified grouping logic for education levels\n",
    "def education_group(edu_num):\n",
    "    if edu_num <= 10:\n",
    "        return 'Low'\n",
    "    elif edu_num <= 13:\n",
    "        return 'Medium'\n",
    "    else:\n",
    "        return 'High'\n",
    "\n",
    "X_train['edu_group'] = X_train['education-num'].apply(education_group)\n",
    "X_test['edu_group'] = X_test['education-num'].apply(education_group)\n",
    "\n",
    "# Simplified grouping logic for working hours\n",
    "def hour_group(hours):\n",
    "    if hours < 40:\n",
    "        return 'Part-time'\n",
    "    elif hours <= 45:\n",
    "        return 'Full-time'\n",
    "    else:\n",
    "        return 'Overtime'\n",
    "\n",
    "X_train['hour_group'] = X_train['hours-per-week'].apply(hour_group)\n",
    "X_test['hour_group'] = X_test['hours-per-week'].apply(hour_group)\n",
    "\n",
    "# Encode categorical variables\n",
    "le = LabelEncoder()\n",
    "categorical_features = X_train.select_dtypes(include=['object', 'category']).columns\n",
    "for feature in categorical_features:\n",
    "    X_train[feature] = le.fit_transform(X_train[feature].astype(str))\n",
    "    X_test[feature] = le.transform(X_test[feature].astype(str))\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train.drop(['edu_group', 'hour_group'], axis=1))\n",
    "X_test_scaled = scaler.transform(X_test.drop(['edu_group', 'hour_group'], axis=1))\n",
    "\n",
    "with mlflow.start_run(run_name=\"Experiment_7_Education_Hours_Analysis\"):\n",
    "    # Train models for each education and hour group combination\n",
    "    edu_groups = ['Low', 'Medium', 'High']\n",
    "    hour_groups = ['Part-time', 'Full-time', 'Overtime']\n",
    "    \n",
    "    min_samples_threshold = 10  # Minimum number of samples required per group\n",
    "    \n",
    "    valid_f1_scores = []\n",
    "    valid_groups = []\n",
    "    \n",
    "    for edu in edu_groups:\n",
    "        for hour in hour_groups:\n",
    "            train_mask = (X_train['edu_group'] == edu) & (X_train['hour_group'] == hour)\n",
    "            test_mask = (X_test['edu_group'] == edu) & (X_test['hour_group'] == hour)\n",
    "            \n",
    "            X_train_group = X_train_scaled[train_mask]\n",
    "            y_train_group = y_train[train_mask]\n",
    "            X_test_group = X_test_scaled[test_mask]\n",
    "            y_test_group = y_test[test_mask]\n",
    "            \n",
    "            # Check if the group has enough samples\n",
    "            if len(X_train_group) >= min_samples_threshold and len(X_test_group) >= min_samples_threshold:\n",
    "                rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "                rf.fit(X_train_group, y_train_group)\n",
    "                \n",
    "                y_pred_test = rf.predict(X_test_group)\n",
    "                \n",
    "                f1 = f1_score(y_test_group, y_pred_test, average='weighted')\n",
    "                \n",
    "                group_name = f\"{edu}_{hour}\"\n",
    "                mlflow.log_metric(f\"f1_score_{group_name}\", f1)\n",
    "                \n",
    "                valid_f1_scores.append(f1)\n",
    "                valid_groups.append(group_name)\n",
    "                \n",
    "                print(f\"Education: {edu}, Hours: {hour}\")\n",
    "                print(f\"F1 Score: {f1:.4f}\")\n",
    "                print(f\"Samples: Train - {len(X_train_group)}, Test - {len(X_test_group)}\")\n",
    "                print()\n",
    "            else:\n",
    "                # Log skipped groups due to insufficient samples\n",
    "                group_name = f\"{edu}_{hour}\"\n",
    "                mlflow.log_param(f\"skipped_{group_name}\", True)\n",
    "                print(f\"Skipping Education: {edu}, Hours: {hour} due to insufficient samples\")\n",
    "    \n",
    "    # Plot F1 scores for valid groups only\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.bar(valid_groups, valid_f1_scores)\n",
    "    plt.title('F1 Scores by Education Level and Working Hours')\n",
    "    plt.xlabel('Education Level - Working Hours')\n",
    "    plt.ylabel('F1 Score')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('edu_hours_f1_scores.png')\n",
    "    mlflow.log_artifact('edu_hours_f1_scores.png')\n",
    "    plt.close()\n",
    "\n",
    "    # Log the overall model trained on all data\n",
    "    overall_rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    overall_rf.fit(X_train_scaled, y_train)\n",
    "    mlflow.sklearn.log_model(overall_rf, \"overall_model\")\n",
    "\n",
    "print(\"Experiment 7 completed and logged to MLflow\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "4f9da46f-c255-4fe1-9cb5-d27624068690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['final_model.joblib']"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Assuming 'best_model' is your trained model\n",
    "best_model = VotingClassifier(estimators=[])  # Replace with your actual model\n",
    "joblib.dump(best_model, 'final_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c42ff7-7657-498b-a901-3475afcbd6ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea77bcdf-5880-4b8f-9cd8-22913e129ea7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b96250-41d1-4ccb-890b-7184ebe9b62e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
